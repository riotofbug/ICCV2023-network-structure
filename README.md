# ICCV2023-network-structure
ICCV2023-network-structure

[1] **Adding Conditional Control to Text-to-Image Diffusion Models**  
  - **Authors:** Lvmin Zhang, Anyi Rao, Maneesh Agrawala
  - **Affiliations:**
    -  Stanford University
  - **Keywords:** Diffusion Models
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf), [[code]](https://github.com/lllyasviel/controlnet)

[2] **Segment Anything**  
  - **Authors:** Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick
  - **Affiliations:**
    -  Meta AI Research
    -  FAIR
  - **Keywords:** image segmentation
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Kirillov_Segment_Anything_ICCV_2023_paper.pdf), [[code]](https://github.com/facebookresearch/segment-anything)

[3] **LFS-GAN: Lifelong Few-Shot Image Generation**  
  - **Authors:** Juwon Seo, Ji-Su Kang, Gyeong-Moon Park
  - **Affiliations:**
    -  Kyung Hee University, Yongin, Republic of Korea
    -  KLleon Tech., Seoul, Republic of Korea
  - **Keywords:** GAN
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf), [[code]](https://github.com/jjuon/lfs-gan)

[4] **Improving Diversity in Zero-Shot GAN Adaptation with Semantic Variations**  
  - **Authors:** Seogkyu Jeon, Bei Liu, Pilhyeon Lee, Kibeom Hong, Jianlong Fu, Hyeran Byun
  - **Affiliations:**
    -  Yonsei University
    -  Microsoft Research Asia
    -  SwatchOn
  - **Keywords:** GAN
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Jeon_Improving_Diversity_in_Zero-Shot_GAN_Adaptation_with_Semantic_Variations_ICCV_2023_paper.pdf), [code]

[5] **AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks**  
  - **Authors:** Kibeom Hong, Seogkyu Jeon, Junsoo Lee, Namhyuk Ahn, Kunhee Kim, Pilhyeon Lee, Daesik Kim, Youngjung Uh, Hyeran Byun
  - **Affiliations:**
    -  Yonsei University
    -  KAIST AI
    -  SwatchOn
    -  NAVER WEBTOON AI
  - **Keywords:** attention mechanism,self-supervisory task,style transfer
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_AesPA-Net_Aesthetic_Pattern-Aware_Style_Transfer_Networks_ICCV_2023_paper.pdf), [[code]](https://github.com/kibeom-hong/aespa-net)

[6] **StyleDiffusion: Controllable Disentangled Style Transfer via Diffusion Models**  
  - **Authors:** Zhizhong Wang, Lei Zhao, Wei Xing
  - **Affiliations:**
    -  College of Computer Science and Technology, Zhejiang University
  - **Keywords:** Content and style (C-S) disentanglement,style transfer,diffusion model
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_StyleDiffusion_Controllable_Disentangled_Style_Transfer_via_Diffusion_Models_ICCV_2023_paper.pdf), [code]

[7] **Spatio-temporal Prompting Network for Robust Video Feature Extraction**  
  - **Authors:** Guanxiong Sun, Chi Wang, Zhaoyu Zhang, Jiankang Deng, Stefanos Zafeiriou, Yang Hua
  - **Affiliations:**
    -  Queen’s University Belfast
    -  Huawei UKRD
    -  Imperial College London
  - **Keywords:** video object detection, video instance segmentation,visual object tracking
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatio-temporal_Prompting_Network_for_Robust_Video_Feature_Extraction_ICCV_2023_paper.pdf), [[code]](https://github.com/guanxiongsun/STPN)

[8] **EMMN: Emotional Motion Memory Network for Audio-driven Emotional Talking Face Generation**  
  - **Authors:** Shuai Tan, Bin Ji, Ye Pan
  - **Affiliations:**
    -  Shanghai Jiao Tong University
  - **Keywords:** Synthesizing expression
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.pdf), [[code]](https://github.com/tanshuai0219/EMMN)

[9] **Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation**  
  - **Authors:** Fa-Ting Hong, Dan Xu
  - **Affiliations:**
    -  CSE, HKUST
  - **Keywords:** talking head generation
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Hong_Implicit_Identity_Representation_Conditioned_Memory_Compensation_Network_for_Talking_Head_ICCV_2023_paper.pdf), [[code]](https://github.com/harlanhong/iccv2023-mcnet)

[10] **Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network**  
  - **Authors:** Yinglong Wang, Zhen Liu, Jianzhuang Liu, Songcen Xu, Shuaicheng Liu
  - **Affiliations:**
    -  Meituan Inc.
    -  Megvii Technology
    -  Shenzhen Institute of Advanced Technology
    -  Huawei Noah’s Ark Lab
    -  University of Electronic Science and Technology of China
  - **Keywords:** low-light image enhancement
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.pdf), [code]

[11] **LAN-HDR: Luminance-based Alignment Network for High Dynamic Range Video Reconstruction**  
  - **Authors:** Haesoo Chung, Nam Ik Cho
  - **Affiliations:**
    -  Department of Electrical and Computer Engineering, INMC, Seoul National University, Korea
    -  IPAI, Seoul National University, Korea
  - **Keywords:** HDR video composition
  - **links**: [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Chung_LAN-HDR_Luminance-based_Alignment_Network_for_High_Dynamic_Range_Video_Reconstruction_ICCV_2023_paper.pdf), [[code]](https://github.com/haesoochung/LAN-HDR)
